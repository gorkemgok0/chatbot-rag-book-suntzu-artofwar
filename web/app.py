"""
Sun Tzu RAG Chatbot - Streamlit Web ArayÃ¼zÃ¼
Sun Tzu'nun SavaÅŸ SanatÄ± Ã¶ÄŸretilerine dayalÄ± akÄ±llÄ± sohbet asistanÄ±
"""

import streamlit as st
import os
from dotenv import load_dotenv
import google.generativeai as genai
import chromadb
from sentence_transformers import SentenceTransformer
import time

# Sayfa yapÄ±landÄ±rmasÄ±
st.set_page_config(
    page_title="Sun Tzu Chatbot", 
    page_icon="âš”ï¸", 
    layout="centered",
    initial_sidebar_state="expanded"
)

@st.cache_resource
def load_rag_components():
    """
    RAG bileÅŸenlerini yÃ¼kler ve cache'ler
    """
    # Ortam deÄŸiÅŸkenlerini yÃ¼kle
    load_dotenv()
    api_key = os.getenv("GOOGLE_API_KEY")
    
    # API key kontrolÃ¼
    if not api_key:
        st.error("GOOGLE_API_KEY bulunamadÄ±! LÃ¼tfen .env dosyasÄ±nda API key'inizi ayarlayÄ±n.")
        return None, None, None, None
    
    if not api_key:
        st.error("GOOGLE_API_KEY bulunamadÄ±! .env dosyasÄ±nÄ± kontrol edin.")
        return None, None, None, None
    
    # Gemini yapÄ±landÄ±rmasÄ±
    genai.configure(api_key=api_key)
    
    # Model kontrolÃ¼ ve seÃ§imi
    try:
        models = genai.list_models()
        available_models = [m.name for m in models if 'generateContent' in m.supported_generation_methods]
        
        # En uygun modeli seÃ§
        if "models/gemini-1.5-flash-latest" in available_models:
            MODEL_NAME = "gemini-1.5-flash-latest"
        elif "models/gemini-1.5-flash" in available_models:
            MODEL_NAME = "gemini-1.5-flash"
        elif "models/gemini-flash-latest" in available_models:
            MODEL_NAME = "gemini-flash-latest"
        else:
            MODEL_NAME = available_models[0] if available_models else "gemini-1.5-flash-latest"
            
        print(f"SeÃ§ilen model: {MODEL_NAME}")
    except Exception as e:
        print(f"Model listesi alÄ±namadÄ±: {e}")
        MODEL_NAME = "gemini-1.5-flash-latest"
    embedder = SentenceTransformer("sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2")
    
    # ChromaDB baÄŸlantÄ±sÄ± (kalÄ±cÄ± veritabanÄ±)
    chroma_client = chromadb.PersistentClient(path="./chroma_db")
    
    try:
        collection = chroma_client.get_collection("sun_tzu_collection")
    except:
        st.warning("ChromaDB koleksiyonu bulunamadÄ±, yeniden oluÅŸturuluyor...")
        
        # Embedding'i yeniden oluÅŸtur
        try:
            with open("sun_tzu.txt", "r", encoding="utf-8") as f:
                texts = [t.strip() for t in f.readlines() if t.strip() and len(t.strip()) > 10]
            
            collection = chroma_client.create_collection(name="sun_tzu_collection")
            
            # Embedding'leri oluÅŸtur
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            for i, text in enumerate(texts):
                emb = embedder.encode(text).tolist()
                collection.add(
                    ids=[str(i)],
                    embeddings=[emb],
                    documents=[text]
                )
                
                # Progress bar gÃ¼ncelle
                progress = (i + 1) / len(texts)
                progress_bar.progress(progress)
                status_text.text(f"Embedding oluÅŸturuluyor... {i+1}/{len(texts)}")
            
            progress_bar.empty()
            status_text.empty()
            
        except Exception as e:
            st.error(f"Embedding oluÅŸturulamadÄ±: {str(e)}")
            return None, None, None, None
    
    # Gemini modeli
    model = genai.GenerativeModel(MODEL_NAME)
    
    return model, embedder, collection, MODEL_NAME

def get_response(model, embedder, collection, query):
    """
    RAG pipeline ile cevap Ã¼retir
    """
    try:
        # Retriever kÄ±smÄ±
        query_emb = embedder.encode(query).tolist()
        results = collection.query(query_embeddings=[query_emb], n_results=3)
        context = "\n\n".join(results["documents"][0])
        
        # Prompt oluÅŸtur
        prompt = f"""
Sen Sun Tzu'nun SavaÅŸ SanatÄ± konusunda uzman bir asistan olarak gÃ¶rev yapÄ±yorsun. 
AÅŸaÄŸÄ±daki baÄŸlamda (context) Sun Tzu'nun Ã¶ÄŸretileri yer almaktadÄ±r.

BaÄŸlam:
{context}

Soru: {query}

LÃ¼tfen bu baÄŸlamdaki bilgilere dayanarak kÄ±sa ve anlaÅŸÄ±lÄ±r bir yanÄ±t ver. 
Sun Tzu'nun Ã¶ÄŸretilerini kullanarak pratik Ã¶neriler sun.
EÄŸer baÄŸlamda doÄŸrudan bilgi yoksa, benzer konulardaki Ã¶ÄŸretileri kullanarak yanÄ±t ver.
"""
        
        # Gemini API Ã§aÄŸrÄ±sÄ±
        response = model.generate_content(prompt)
        return response.text, context
        
    except Exception as e:
        return f"ÃœzgÃ¼nÃ¼m, bir hata oluÅŸtu: {str(e)}", ""

def main():
    """
    Ana uygulama fonksiyonu
    """
    # BaÅŸlÄ±k ve aÃ§Ä±klama
    st.title("âš”ï¸ Sun Tzu - SavaÅŸ SanatÄ± Chatbot")
    st.markdown("---")
    st.markdown("**Sun Tzu'nun Ã¶ÄŸretilerine dayalÄ± akÄ±llÄ± bir sohbet asistanÄ±**")
    st.markdown("SavaÅŸ stratejisi, liderlik, taktik ve stratejik dÃ¼ÅŸÃ¼nce konularÄ±nda sorularÄ±nÄ±zÄ± sorun!")
    
    # Sidebar
    with st.sidebar:
        st.header("ğŸ“š HakkÄ±nda")
        st.markdown("""
        Bu chatbot, Sun Tzu'nun **SavaÅŸ SanatÄ±** eserinin TÃ¼rkÃ§e Ã§evirisini 
        kullanarak RAG (Retrieval-Augmented Generation) teknolojisi ile Ã§alÄ±ÅŸÄ±r.
        
        **Teknoloji Stack:**
        - ğŸ¤– Gemini 1.5 Flash (LLM)
        - ğŸ§  Sentence Transformers (Embedding)
        - ğŸ—„ï¸ ChromaDB (Vector Database)
        - ğŸš€ Streamlit (Web ArayÃ¼zÃ¼)
        """)
        
        st.header("ğŸ’¡ Ã–rnek Sorular")
        example_questions = [
            "SavaÅŸta strateji nasÄ±l belirlenir?",
            "DÃ¼ÅŸman nasÄ±l yenilir?",
            "Ordunun moralini nasÄ±l yÃ¼kseltirsin?",
            "KaynaklarÄ± nasÄ±l yÃ¶netirsin?",
            "Liderlik nasÄ±l olmalÄ±dÄ±r?",
            "Ne zaman savaÅŸmamak gerekir?"
        ]
        
        for question in example_questions:
            if st.button(f"â“ {question}", key=f"example_{question}"):
                st.session_state.user_input = question
                st.rerun()
    
    # RAG bileÅŸenlerini yÃ¼kle
    with st.spinner("RAG sistemi yÃ¼kleniyor..."):
        model, embedder, collection, model_name = load_rag_components()
    
    if not all([model, embedder, collection]):
        st.error("RAG sistemi yÃ¼klenemedi! LÃ¼tfen konsol Ã§Ä±ktÄ±sÄ±nÄ± kontrol edin.")
        return
    
    # KullanÄ±cÄ± girdisi
    st.markdown("### ğŸ’¬ Soru Sor")
    
    # Ã–rnek soru butonundan gelen deÄŸer
    default_value = st.session_state.get('user_input', '')
    if default_value:
        st.session_state.user_input = ''  # Reset
    
    query = st.text_input(
        "Sun Tzu'nun Ã¶ÄŸretileri hakkÄ±nda bir soru sorun:",
        value=default_value,
        placeholder="Ã–rn: SavaÅŸta strateji nasÄ±l belirlenir?",
        help="SavaÅŸ stratejisi, liderlik, taktik veya stratejik dÃ¼ÅŸÃ¼nce konularÄ±nda soru sorabilirsiniz."
    )
    
    if query:
        with st.spinner("DÃ¼ÅŸÃ¼nÃ¼yorum..."):
            # RAG pipeline ile cevap Ã¼ret
            response, context = get_response(model, embedder, collection, query)
        
        # YanÄ±tÄ± gÃ¶ster
        st.markdown("### ğŸ¯ Cevap")
        st.markdown(response)
        
        # KaynaklarÄ± gÃ¶ster (geniÅŸletilebilir)
        if context:
            with st.expander("ğŸ“š KullanÄ±lan Kaynak Metinler"):
                st.text_area("BaÄŸlam:", context, height=200, disabled=True)
            
            # Performans bilgisi
            st.markdown("---")
            st.markdown("**ğŸ’¡ Bu cevap Sun Tzu'nun SavaÅŸ SanatÄ± eserinden alÄ±nan metinler temel alÄ±narak Ã¼retilmiÅŸtir.**")
    
    # Alt bilgi
    st.markdown("---")
    st.markdown(
        """
        <div style='text-align: center; color: #666;'>
            <small>Sun Tzu RAG Chatbot | RAG + Gemini + Streamlit</small>
        </div>
        """, 
        unsafe_allow_html=True
    )

if __name__ == "__main__":
    main()